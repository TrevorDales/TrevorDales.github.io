<!doctype html><html lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><title>
        Lab 7
    </title><link href="https://TrevorDales.github.io/ atom.xml" title="Trevor Dales" rel=alternate type=application/atom+xml><link href=https://TrevorDales.github.io/main.css media=screen rel=stylesheet><meta content="Hi! My name is Trevor." name=description><meta content="Hi! My name is Trevor." name=description><meta content="index, nofollow" name=robots><meta content="Trevor Dales" property=og:title><meta content=article property=og:type><meta content=https://TrevorDales.github.io/MAE4190/lab7/ property=og:url><meta content="Hi! My name is Trevor." property=og:description><meta content="Trevor Dales" property=og:site_name><meta content="default-src 'self' ws://127.0.0.1:1024/; img-src 'self' https://*; script-src 'self'; style-src 'self'; font-src 'self'; frame-src https://www.youtube.com https://player.vimeo.com;" http-equiv=Content-Security-Policy><body><header><div class=navbar><div class="nav-title nav-navs"><a class="nav-links home-title" href=https://TrevorDales.github.io>Trevor Dales</a></div><nav class="nav-title nav-navs"><a class=nav-links href=/MAE4190> <img 4190 alt=MAE height=15 src=/menu_icon/projects.png width=15> MAE 4190</a><a class=nav-links href=/contact/contact> <img alt=Contact height=15 src=/menu_icon/resume.png width=15> Contact</a></nav><nav class="socials nav-navs"><label class=theme-switcher for=themeswitch><div class=background></div> <input id=themeswitch type=checkbox> <div class=switch><img alt="theme switch to dark" class=moon src=/menu_icon/moon.png><img alt="theme switch to light" class=sun src=/menu_icon/sun.png></div></label></nav></div></header><div class=content><main><article><div class=title><h2>Lab 7</h2><div class=meta>Posted on <time>2025-03-24</time></div></div><section class=body><h1 id=estimating-mass-and-drag>Estimating Mass and Drag</h1><p>To build the state space model for my robot, I first needed to accurately estimate the mass and drag acting on my car. Following the derivation outlined in <a href=https://fastrobotscornell.github.io/FastRobots-2025/lectures/FastRobots2025_Lecture13_Observability.pdf>Farrell's Lecture 13</a>, the dynamics of the system can be expressed as follows:<div align=center><img src=/Lab7/system_dynamics.png style=display:block></div><br> Now considering a step response from rest to a steady state velocity, acceleration is zero once this velocity is reached. The d and m terms can then be solved for: <div align=center><img src=/Lab7/solve_for_d.png style=display:block></div><br><p>d and m are lumped parameters that capture the dynamics of the system - how the car responds to control inputs and moves through the world. u<sub>ss</sub> is the constant control input being passed to the robot for this test. I decided to use an input of 1, corresponding to the maximum pwm signal possible (255). I did this because I wanted my dynamics to be accurate when my robot is moving quickly, as this is the ideal behavior of an accurate controller.<div align=center><iframe <pre class=z-code height=315 src=https://www.youtube.com/embed/EpUNBuIomIE width=175><code><span class="z-text z-plain">allowfullscreen> </span></code></iframe><h5 id=step-response-test>Step Response Test</h5></div><br> With this TOF data, I was able to calculate the velocity at each time step: <pre class=z-code><code><span class="z-text z-plain"># Compute velocity (finite difference method)
</span><span class="z-text z-plain">velocity_values = []
</span><span class="z-text z-plain">for i in range(len(tof2_time_values) - 1):  # Loop over indices
</span><span class="z-text z-plain">    if (tof2_time_values[i] == tof2_time_values[0]):
</span><span class="z-text z-plain">        dt = 1
</span><span class="z-text z-plain">        dd = .000001
</span><span class="z-text z-plain">    else:
</span><span class="z-text z-plain">        dt = tof2_time_values[i] - tof2_time_values[i-1]  # Time difference
</span><span class="z-text z-plain">        dd = tof2_values[i] - tof2_values[i-1]  # Distance difference
</span><span class="z-text z-plain">    
</span><span class="z-text z-plain">    velocity = dd / dt  # Velocity calculation
</span><span class="z-text z-plain">    velocity_values.append(round(velocity,3))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">velocity_values.append(0) # ensure arrays of equal length
</span></code></pre><p>One problem I ran into is that my high step input meant that the robot needed to drive for a long distance in order to reach anywhere near its maximum speed. This was exacerbated by the fact that my front TOF only reliably worked up to 2000mm rather than the expected 4000mm. <br><p>My solution to this was to run multiple tests, starting from different distances to the wall. I then made the assumption that each test would have the same position and velocity curve shapes. Even though I would only get good readings under 2000mm from the wall, I was able to manually combine the data from multiple tests into one comprehensive position curve.<div align=center><img src=/Lab7/close_test.png style=display:block><h5 id=close-test-small-correction-velocity-units-are-in-m-s>Close Test - **small correction, velocity units are in m/s</h5></div><br><div align=center><img src=/Lab7/mid_test.png style=display:block><h5 id=mid-test-note-the-bad-readings-above-2000mm>Mid Test - note the bad readings above 2000mm</h5></div><br><div align=center><img src=/Lab7/long_test.png style=display:block><h5 id=long-test-note-the-bad-readings-above-2000mm>Long Test - note the bad readings above 2000mm</h5></div><br><p>Combining the velocity data from the valid parts of these trials into one comprehensive step response allowed me to get a better idea of how the car was slowing down:<div align=center><img src=/Lab7/combined_velocity.png style=display:block><h5 id=combined-velocity-data-m-s-vs-ms>Combined Velocity Data - m/s vs ms</h5></div><br><p>With this data, I then used the curve_fit function within the scipy.optimize module of scipy to fit an exponential decay curve to the data. Using this, I was able to find the steady state velocity, as well as the 90% rise time and velocity.<pre class=z-code><code><span class="z-text z-plain"># Define the exponential decay function
</span><span class="z-text z-plain">def exponential_func(x, a, b, c):
</span><span class="z-text z-plain">    return a * np.exp(b * x) + c
</span><span class="z-text z-plain">
</span><span class="z-text z-plain"># Fit the curve
</span><span class="z-text z-plain">popt, _ = curve_fit(exponential_func, combined_time, combined_velocity, p0=(1, -0.001, -3))
</span><span class="z-text z-plain">a, b, c = popt
</span><span class="z-text z-plain">
</span><span class="z-text z-plain"># Generate fitted curve
</span><span class="z-text z-plain">x_fit = np.linspace(min(combined_time), max(combined_time) + 3000, 1000) # add 3000 to extend the graph beyond my data
</span><span class="z-text z-plain">y_fit = exponential_func(x_fit, *popt)
</span><span class="z-text z-plain">
</span><span class="z-text z-plain"># Calculate Key Metrics
</span><span class="z-text z-plain">t0 = min(combined_time)
</span><span class="z-text z-plain">v0 = exponential_func(t0, *popt)
</span><span class="z-text z-plain">v_ss = c
</span><span class="z-text z-plain">v_90_decay = c + 0.1 * (v0 - c)
</span><span class="z-text z-plain">t_90 = np.log((v_90_decay - c) / a) / b
</span></code></pre><br><div align=center><img src=/Lab7/exponential_fit.png style=display:block></div><p>With these values, I then calculated d and m using the equations found above.</p><br><div align=center><img src=/Lab7/d_and_m.png style=display:block></div><br><br><h1 id=simulating-the-kalman-filter>Simulating the Kalman Filter</h1><p>In order to implement the Kalman Filter (KF) in python, I first transfered our dynamics into state space.<div align=center><img src=/Lab7/state_space.png style=display:block></div><pre class=z-code><code><span class="z-text z-plain">A = np.array([
</span><span class="z-text z-plain">    [0, 1],
</span><span class="z-text z-plain">    [0, d/m]
</span><span class="z-text z-plain">])
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">B = np.array([
</span><span class="z-text z-plain">    [0],
</span><span class="z-text z-plain">    [1/m]
</span><span class="z-text z-plain">])
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">C = np.array([[1, 0]])
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">x = np.array([[distance[0]], [0]]) # Initialize state vector
</span></code></pre><p>I then discretized the matrices. I used a dt of 100ms, because that matched my sensor speed pretty closely. I also defined the steady control input here.<pre class=z-code><code><span class="z-text z-plain">Ad = np.eye(n) + dt * A  
</span><span class="z-text z-plain">Bd = dt * B
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">u_ss = -1
</span></code></pre><p>Next I initialized my covariance matrices. I initially tried to use the formulas to calculate these, as well as referencing my lab 3 experimentation that found the standard deviation of the TOF sensor; however, I found trial and error to be the best method in this case.<pre class=z-code><code><span class="z-text z-plain"># Process noise
</span><span class="z-text z-plain">sigma_1 = .10 # position variance
</span><span class="z-text z-plain">sigma_2 = 100 # speed variance
</span><span class="z-text z-plain">
</span><span class="z-text z-plain"># Sensor noise
</span><span class="z-text z-plain">sigma_3 = 50
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">Sigma_u = np.array([[sigma_1**2, 0], [0, sigma_2**2]]) # confidence in model
</span><span class="z-text z-plain">Sigma_z = np.array([[sigma_3**2]]) # confidence in measurements
</span></code></pre><br> After defining all of the variables, I implemented the filter logic using the lecture example as a guide. <pre class=z-code><code><span class="z-text z-plain">def kalman(mu, sigma, u, y, update = True):
</span><span class="z-text z-plain">    mu_p = Ad.dot(mu) + Bd.dot(u)
</span><span class="z-text z-plain">    sigma_p = Ad.dot(sigma.dot(Ad.transpose())) + Sigma_u
</span><span class="z-text z-plain">    if not update:
</span><span class="z-text z-plain">        return mu_p, sigma_p
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    #run only if new measurement
</span><span class="z-text z-plain">    sigma_m = C.dot(sigma_p.dot(C.transpose())) + Sigma_z
</span><span class="z-text z-plain">    kkf_gain = sigma_p.dot(C.transpose().dot(np.linalg.inv(sigma_m)))
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    y_m = y - C.dot(mu_p)
</span><span class="z-text z-plain">    mu = mu_p + kkf_gain.dot(y_m)
</span><span class="z-text z-plain">    sigma = (np.eye(2) - kkf_gain.dot(C)).dot(sigma_p)
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    return mu, sigma
</span><span class="z-text z-plain">
</span><span class="z-text z-plain"># Uncertainty for initial state
</span><span class="z-text z-plain">sigma = np.array([[20**2, 0], [0, 10**2]])
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">kf = []
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">i = 0
</span><span class="z-text z-plain">for t in time:
</span><span class="z-text z-plain">    # Step through discrete time
</span><span class="z-text z-plain">    update = time[i+1] <= t
</span><span class="z-text z-plain">    i += 1 if update else 0
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    # Run Kalman filter for each time step
</span><span class="z-text z-plain">    x, sigma = kalman(x, sigma, u_ss, distance[i], update)
</span><span class="z-text z-plain">    kf.append(x[0])
</span></code></pre><p>When trusting the sensor measurements more than the process, the result was a filter that followed the data pretty closely. To much trust could lead to a filter at the mercy of sensor noise.<div align=center><img src=/Lab7/trust_sensor_kalman.png style=display:block><h5 id=sigma-1-250-sigma-2-250-sigma-3-100>sigma_1 = 250, sigma_2 = 250, sigma_3 = 100</h5></div><br> However, trusting the filter more lead to bigger discrepancies between the data and filter. <div align=center><img src=/Lab7/distrust_sensor_kalman.png style=display:block><h5 id=sigma-1-100-sigma-2-100-sigma-3-400>sigma_1 = 100, sigma_2 = 100, sigma_3 = 400</h5></div><br><h1 id=interpolation>Interpolation</h1><p>Running the KF at the speed of the TOF sensor works, but it doesn't really add much useful information for my robot's behavior. In order to be impactful, the KF needs to be able to run faster than the sensors, filling in the gaps between measurements with a more accurate model than just linear interpolation. To get this working in my simulator, I defined a higher resolution time span and looped through that instead. I also changed dt to 15ms to match the approximate speed of my PID loop on the artemis.<pre class=z-code><code><span class="z-text z-plain">i = 0
</span><span class="z-text z-plain">interval = .015 # ms
</span><span class="z-text z-plain">steps = np.arange(0, (time[-1] ), interval)
</span><span class="z-text z-plain">for t in steps:
</span><span class="z-text z-plain">    # Step through discrete time
</span><span class="z-text z-plain">    update = time[i+1] <= t
</span><span class="z-text z-plain">    i += 1 if update else 0
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    # Run Kalman filter for each time step
</span><span class="z-text z-plain">    x, sigma = kalman(x, sigma, u_ss, distance[i], update)
</span><span class="z-text z-plain">    kf.append(x[0])
</span></code></pre><div align=center><img src=/Lab7/kalman_interp.png style=display:block></div><br><p>Some debugging notes - I was running into some unit issues that would throw off my calculated dynamics. I fixed this by going through my entire setup and making sure every unit was unscaled (meters, seconds, kilograms only). Also, I found that setting the sensor uncertainty to an astronomically high number was a very useful debugging step. This meant the filter would ignore the sensor data, and I could get a good idea of the motion that the filter would predict using just the system dynamics and control input.<div align=center><img src=/Lab7/kalman_debug.png style=display:block><h5 id=note-how-the-filter-completely-ignores-the-sensor-data-this-filter-is-pretty-well-tuned-as-the-predicted-motion-mostly-matches-the-actual-motion-even-without-any-actual-fusion-between-the-two>Note how the filter completely ignores the sensor data. This filter is pretty well tuned, as the predicted motion mostly matches the actual motion even without any actual fusion between the two.</h5></div> I used this sensor ignoring debugging step even on my real robot, to again see how just the filter was behaving. Without this step, it was easy to falsely assume the filter was performing well - when in reality, it might have just been blindly following the sensor data rather than accurately modeling the systemâ€™s behavior. <br><br><h1 id=implementation-on-my-robot>Implementation On My Robot</h1><p>When sending the BLE command to my car, I made sure to make all of the tunable parameters changeable on the python side. This made tuning much quicker, as I didn't have to upload new artemis code for small changes.<pre class=z-code><code><span class="z-text z-plain">kp = 0.1
</span><span class="z-text z-plain">ki = 0
</span><span class="z-text z-plain">kd = .004
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">target = 300 # [mm]
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">d = -0.209
</span><span class="z-text z-plain">m = 0.213
</span><span class="z-text z-plain">uf = 1000 # control input scale factor
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">sig1 = .10
</span><span class="z-text z-plain">sig2 = 100
</span><span class="z-text z-plain">sig3 = 50
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">runtime = 6000 # [ms]
</span></code></pre><br> The logic of the KF didn't change - it just needed to be refactored for matrix operations in C. The general structure was a BLE command that sends all of the parameters; within this command a loop runs that repeatedly calls functions that collect data (TOF), predict motion (KF), and calculate/send control inputs (PID). <p>I also made use of global variables whenever possible to simplify the arguments passed between functions.<p>I implemented this with the KF interpolating between measurements, allowing the robot to adjust control inputs very quickly (the speed of the loop was about 10ms).<pre class=z-code><code><span class="z-text z-plain">while (millis() - start_time < runtime) //run for a fixed amount of time
</span><span class="z-text z-plain">{
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    // attempt to refresh sensor data
</span><span class="z-text z-plain">    if ( (tof1Counter < MAX_TIME_STAMPS) && (tof2Counter < MAX_TIME_STAMPS)  ) 
</span><span class="z-text z-plain">        {
</span><span class="z-text z-plain">        collect_tof();
</span><span class="z-text z-plain">        }
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    // predict new distance value
</span><span class="z-text z-plain">    kalman(x, sigma, Ad, Bd, Sigma_u, Sigma_z, C, uf);
</span><span class="z-text z-plain">    float current_distance = tof_kalman[pidCounter];
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    // calculate error    
</span><span class="z-text z-plain">    float error = current_distance - target;
</span><span class="z-text z-plain">    float prev_error = tof_kalman[pidCounter-1] - target;
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    // calculate PID input and send to motors
</span><span class="z-text z-plain">    pid_control_input[pidCounter] = send_control_input(kp, ki, kd, error, prev_error, df_alpha);
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">    // update time array + counter
</span><span class="z-text z-plain">    pid_time_stamps[pidCounter] = millis();
</span><span class="z-text z-plain">    pidCounter = pidCounter + 1; 
</span><span class="z-text z-plain">
</span><span class="z-text z-plain">}
</span></code></pre><br><p>When tuning my controller, there were many parameters to consider:<ul><li><p>Kp and Kd (I left out an integrator term for this lab; e<sub>ss</sub> was low). The gains had the same effect as in the previous PID lab. The added challenge was that each time a new sensor value came in, the filtered data would jump to adjust to this, causing a derivative spike. I added a LPF to deal with this noise.</p><li><p>Measurement uncertainty. Lowering the sensor uncertainty led to a filter that followed the TOF sensors very closely - making this too low would mean the filter was subject to the same noise as the sensors. Too high, and the filter may drift too far away from the actual values.</p><li><p>Process uncertainty. Sig1 and sig2 represent the uncertainty in the process model for position and velocity, respectively. Low values for these parameters indicate high confidence in the model's predictions, causing the filter to rely more on its internal dynamics and respond less to sensor updates. High values signal low trust in the model, making the filter lean more heavily on sensor measurements. Risks and benefits of over/undertuning are similar to that of measurement uncertainty.</p><li><p>m and d. While these terms were estimated from experimental trials, they could still be tweaked. A larger m meant that the dynamics represented a car with more inertia - a control input would accelerate the car less. d plays more of a role scaling the maximum velocity and also how quickly speed decays when a control input is removed.</p><li><p>u. While the control input comes from the PID controller and probably should not technically be changed, I found it an easy "hack" for getting closer to my desired filter behavior. This could probably be replicated by tweaking m and d, or perhaps I have a unit issue. However, I added a standalone scaling factor to my control input - it still came from my controller, but I just found that amplifying its value allowed it to have the desired effect on the predicted trajectory.</p></ul><p>With all of this in mind, I spent some time tuning my controller and KF. This was my final result:<div align=center><iframe <pre class=z-code height=315 src=https://www.youtube.com/embed/jeKsp6g2Qd8 width=700><code><span class="z-text z-plain">allowfullscreen> </span></code></iframe><img src=/Lab7/final_kalman.png style=display:block><h5></h5></div><br><br><h1 id=collaboration>Collaboration</h1><p>I worked with Jack Long and Lucca Correia extensively. I also referenced Stephan Wagner's site for sense checking my uncertainty values. Lastly, ChatGPT helped me make pretty plots and initialize matrices correctly in C.</section></article></main></div><footer><section><nav><a class="nav-links social" rel="noopener noreferrer" href=https://github.com/TrevorDales target=_blank> <img alt=github src=/social_icons/github.svg title=github> </a></nav><nav><span classname=desktop-only>This blog is powered by <a rel="noopener noreferrer" href=https://getzola.org/ target=_blank>Zola</a> with theme by <a rel="noopener noreferrer" href=https://syedzayyan.com/ target=_blank>SZM</a></span></nav></section><script src=https://TrevorDales.github.io/js/main.js></script></footer>